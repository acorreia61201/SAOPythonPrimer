{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0483f4d",
   "metadata": {
    "id": "c0483f4d"
   },
   "source": [
    "# SAO/LIP Python Primer Course Lecture 7\n",
    "\n",
    "In this notebook, you will learn about:\n",
    "- File paths and the `os` library\n",
    "- I/O in base Python\n",
    "- The `pandas` library\n",
    "- Reading and viewing files in `pandas`\n",
    "- Manipulating datasets\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/acorreia61201/SAOPythonPrimer/blob/main/lectures/Lecture7.ipynb)\n",
    "\n",
    "At the end of our discussion on `numpy`, we started covering the concept of *I/O*, or *input/output*. This is a useful feature that you can use to share or load large datasets. In this lecture, we'll cover two more methods to do this: using base Python, and using an external library `pandas`.\n",
    "\n",
    "## File Paths\n",
    "\n",
    "Before we get into that, it's important that we understand how files are stored on your computer. We can use a library `os` to visualize how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b2111",
   "metadata": {
    "id": "014b2111"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f559709",
   "metadata": {
    "id": "1f559709"
   },
   "source": [
    "All files on an operating system are located in a *directory*, more commonly known as a folder. Directories can contain files or subdirectories, which themselves may have their own files and subdirectories. Each file has a sequence of directories describing where it is on your system known as a *path*.\n",
    "\n",
    "This notebook, for example, has a path. If you're currently viewing this notebook, its path will be the *current working directory*. In Python, we can view the current working directory with `os.getcwd()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade1dfa",
   "metadata": {
    "id": "aade1dfa"
   },
   "outputs": [],
   "source": [
    "lecs = os.getcwd()\n",
    "lecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ed5e81",
   "metadata": {
    "id": "22ed5e81"
   },
   "source": [
    "This current working directory is populated with some files auto-generated by Colab (if you're using that; you may have some other files if you're running locally). To view them all, we use the *list* command which we call in Python with `os.listdir()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db772fb1",
   "metadata": {
    "id": "db772fb1"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dcd237",
   "metadata": {
    "id": "44dcd237"
   },
   "source": [
    "Each file within the same directory has a unique name with two parts. Each file has a *file name*, which itself contains the *file extension*. File extensions can tell your operating system how to interpret and open files. For example, extensions like `png` and `jpg` are interpreted as images, while extensions like `txt` are interpreted as plain-text files. Each lecture above has the extension `ipynb`, the standard for a Jupyter notebook. \n",
    "\n",
    "We can create a new directory in the current working directory using `os.mkdir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a716d3",
   "metadata": {
    "id": "61a716d3"
   },
   "outputs": [],
   "source": [
    "os.mkdir('example_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec14689c",
   "metadata": {
    "id": "ec14689c"
   },
   "source": [
    "We can see the new directory using `os.listdir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56254d",
   "metadata": {
    "id": "da56254d"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40feafa",
   "metadata": {
    "id": "d40feafa"
   },
   "source": [
    "Notice that if we try to add a new directory with the same name we get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afeab91",
   "metadata": {
    "id": "1afeab91"
   },
   "outputs": [],
   "source": [
    "os.mkdir('example_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028cb606",
   "metadata": {
    "id": "028cb606"
   },
   "source": [
    "We can move our current working directory to this new directory using `os.chdir()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccbaf2",
   "metadata": {
    "id": "eeccbaf2"
   },
   "outputs": [],
   "source": [
    "os.chdir('example_dir')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02363b",
   "metadata": {
    "id": "fc02363b"
   },
   "source": [
    "Let's see what's in this new directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de74411",
   "metadata": {
    "id": "0de74411"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514413fc",
   "metadata": {
    "id": "514413fc"
   },
   "source": [
    "It returns an empty list. This makes sense; we haven't added anything to it yet. We can, however, view what's in the previous directory (or any directory on the system, for that matter) using an *absolute path*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9506114",
   "metadata": {
    "id": "e9506114"
   },
   "outputs": [],
   "source": [
    "os.listdir(lecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43aa99",
   "metadata": {
    "id": "5c43aa99"
   },
   "source": [
    "There are two special strings that represent `relative paths` to the current directory. The string `.` refers to the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50553e2",
   "metadata": {
    "id": "e50553e2"
   },
   "outputs": [],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8aa59",
   "metadata": {
    "id": "96e8aa59"
   },
   "source": [
    "The string `..` refers to the directory above the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e78d2",
   "metadata": {
    "id": "8c0e78d2"
   },
   "outputs": [],
   "source": [
    "os.listdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b21231",
   "metadata": {
    "id": "89b21231"
   },
   "source": [
    "We can use this to easily move up one directory in the path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d374a0",
   "metadata": {
    "id": "f4d374a0"
   },
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23957d1e",
   "metadata": {
    "id": "23957d1e"
   },
   "source": [
    "We can also modify currently existing files. If we want to change the name of the directory we just made, we can use `os.rename()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b890fb8",
   "metadata": {
    "id": "5b890fb8"
   },
   "outputs": [],
   "source": [
    "os.rename('example_dir', 'new_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70af5350",
   "metadata": {
    "id": "70af5350"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895d448",
   "metadata": {
    "id": "1895d448"
   },
   "source": [
    "If we want to remove it entirely, we can use `os.remove()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5041c",
   "metadata": {
    "id": "cdd5041c"
   },
   "outputs": [],
   "source": [
    "os.rmdir('new_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad941b4",
   "metadata": {
    "id": "1ad941b4"
   },
   "source": [
    "If we want to remove files, we can instead use `os.remove()`. If you try to remove a directory with this command, you'll get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf4bb2",
   "metadata": {
    "id": "96bf4bb2"
   },
   "outputs": [],
   "source": [
    "os.mkdir('example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c492baf",
   "metadata": {
    "id": "3c492baf"
   },
   "outputs": [],
   "source": [
    "os.remove('example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37624d",
   "metadata": {
    "id": "4c37624d"
   },
   "source": [
    "The same is true in reverse (i.e. using `os.rmdir()` on a file). These are the basics of using `os` to view and manipulate files; the full documentation is at https://docs.python.org/3/library/os.html. (There's a lot here; you may be better off doing your own research if you have a specific thing you want to do.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83bc2e",
   "metadata": {
    "id": "cb83bc2e"
   },
   "source": [
    "## I/O in Base Python\n",
    "\n",
    "Now, let's get to reading and writing files using built-in Python commands. First, we need a file to open. There are two ways to do this. We can download an external file from the internet using the command `wget`. This is a command-line function, so we have to precede it with `!`. For this example, we'll download the Gettysburg Address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49b446",
   "metadata": {
    "id": "1f49b446"
   },
   "outputs": [],
   "source": [
    "!wget https://collincapano.com/wp-content/uploads/2023/01/gettysburg_address-bliss_copy.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c674432",
   "metadata": {
    "id": "4c674432"
   },
   "source": [
    "Let's see if it downloaded properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47292f69",
   "metadata": {
    "id": "47292f69"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f9103d",
   "metadata": {
    "id": "23f9103d"
   },
   "source": [
    "Let's give it a more concise name using `os`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc96e6",
   "metadata": {
    "id": "f1dc96e6"
   },
   "outputs": [],
   "source": [
    "os.rename('gettysburg_address-bliss_copy.txt', 'gettysburg_address.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd94e18",
   "metadata": {
    "id": "4dd94e18"
   },
   "source": [
    "Alternatively, we can create our own file using the function `open()`. This is one of the primary functions used for I/O. As the name implies, its simplest use is to open a file. However, there are a variety of *modes* we can use, accessible via extra arguments. To create a new file, we pass `'x'` as a second argument, indicating create mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfbe52e",
   "metadata": {
    "id": "1cfbe52e"
   },
   "outputs": [],
   "source": [
    "open('new_file.txt', 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b26588",
   "metadata": {
    "id": "f1b26588"
   },
   "source": [
    "Again, we can check that this new file exists using `os`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc6c3f",
   "metadata": {
    "id": "c0dc6c3f"
   },
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3075105d",
   "metadata": {
    "id": "3075105d"
   },
   "source": [
    "### Reading Files\n",
    "\n",
    "Now, let's open the files we've created. We can do this by using `open()` without any extra arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cb8126",
   "metadata": {
    "id": "92cb8126"
   },
   "outputs": [],
   "source": [
    "newfile = open('new_file.txt')\n",
    "gb = open('gettysburg_address.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41887693",
   "metadata": {
    "id": "41887693"
   },
   "source": [
    "By default, `open()` will open a file in read mode. This means that all we can do is look at its contents. To print the contents of a file, we use the method `read()` on one of the objects we've created above. Let's try it with the Gettysburg Address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a25369",
   "metadata": {
    "id": "64a25369"
   },
   "outputs": [],
   "source": [
    "print(gb.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885f10b",
   "metadata": {
    "id": "0885f10b"
   },
   "source": [
    "Another way we can read the contents of a file is with the method `readlines()`, which we'll try out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a1828",
   "metadata": {
    "id": "0b7a1828"
   },
   "outputs": [],
   "source": [
    "gb.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd2cb1",
   "metadata": {
    "id": "72bd2cb1"
   },
   "source": [
    "Nothing printed...what's going on? It turns out that `readlines()` only prints out the lines we haven't viewed yet. Since `read()` with no arguments prints the entire document, additional calls of `read()` will print nothing.\n",
    "\n",
    "To do this, we'll have to create a new `open()` instance. It's good practice to close any documents you've opened once you're done using them so you don't risk losing data. We can do this with the `close()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dae867",
   "metadata": {
    "id": "01dae867"
   },
   "outputs": [],
   "source": [
    "newfile.close()\n",
    "gb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5d200",
   "metadata": {
    "id": "eff5d200"
   },
   "source": [
    "Now, let's open the Gettysburg Address again, this time using `readlines()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3671b15",
   "metadata": {
    "id": "c3671b15"
   },
   "outputs": [],
   "source": [
    "gb = open('gettysburg_address.txt')\n",
    "print(gb.readlines())\n",
    "gb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08ee19b",
   "metadata": {
    "id": "d08ee19b"
   },
   "source": [
    "`readlines()` adds all of the lines in the file to a list as individual elements. However, this includes special characters like `\\n`, which require a `print()` statament to be interpreted. We can fix this by iterating over the list in a loop, just as we've learned before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465089d",
   "metadata": {
    "id": "9465089d"
   },
   "outputs": [],
   "source": [
    "gb = open('gettysburg_address.txt')\n",
    "lines = gb.readlines()\n",
    "for i in lines:\n",
    "    print(i)\n",
    "gb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cf5df8",
   "metadata": {
    "id": "07cf5df8"
   },
   "source": [
    "This is pretty close to what's actually in the file. This also has the benefit of interpreting the `\\n` files as actual line breaks. We can also write this using the method `readline()`, which reads the first line that hasn't been read yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4346fb8d",
   "metadata": {
    "id": "4346fb8d"
   },
   "outputs": [],
   "source": [
    "gb = open('gettysburg_address.txt')\n",
    "line = gb.readline() # placeholder variable starting at first line\n",
    "while line != '': # iterate until reaching an empty line\n",
    "    print(line) # print current line\n",
    "    line = gb.readline() # redefine placeholder as next line\n",
    "gb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31651c18",
   "metadata": {
    "id": "31651c18"
   },
   "source": [
    "`read()` has an optional argument that we can pass to control how much information is printed to screen. Inputting an integer argument into `read()` prints out only that number of bytes, or characters. The default value is -1, which prints out all of the bytes in the file. The same is true for `readline()`, although doing the same for `readlines()` will only print the lines with less than the given number of bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bda211",
   "metadata": {
    "id": "e2bda211"
   },
   "outputs": [],
   "source": [
    "gb = open('gettysburg_address.txt')\n",
    "print(gb.read(5)) # print 5 characters (spaces included)\n",
    "print(gb.read(10)) # print 10 characters\n",
    "print(gb.read(-1)) # print the rest of the characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa35ca",
   "metadata": {
    "id": "92fa35ca"
   },
   "source": [
    "### Writing Files\n",
    "\n",
    "Let's now try printing the contents of `new_file.txt`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e72bf9e",
   "metadata": {
    "id": "5e72bf9e"
   },
   "outputs": [],
   "source": [
    "nf = open('new_file.txt')\n",
    "print(nf.read())\n",
    "nf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74edccf",
   "metadata": {
    "id": "c74edccf"
   },
   "source": [
    "Just as you'd probably expect, the new file is empty. In order to add text to the file, we'll need to make use of the write mode for `open`. We can do this by opening the file with the argument `\"w\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0618c6",
   "metadata": {
    "id": "ee0618c6"
   },
   "outputs": [],
   "source": [
    "nf = open('new_file.txt', 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7201d8",
   "metadata": {
    "id": "5a7201d8"
   },
   "source": [
    "We can now add a line to the file using the method `write()`, with the argument being a string you wish to add to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f80661",
   "metadata": {
    "id": "b6f80661"
   },
   "outputs": [],
   "source": [
    "nf.write('This is a new line of text.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf505df",
   "metadata": {
    "id": "1cf505df"
   },
   "source": [
    "Let's check the file now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c213b",
   "metadata": {
    "id": "c28c213b"
   },
   "outputs": [],
   "source": [
    "nf.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72dc6d",
   "metadata": {
    "id": "6a72dc6d"
   },
   "source": [
    "Oops, remember that we opened the file in write mode only. This means that we can't apply any of the methods we could use in read mode. Let's close this file to save our changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18393c28",
   "metadata": {
    "id": "18393c28"
   },
   "outputs": [],
   "source": [
    "nf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e25bde",
   "metadata": {
    "id": "a3e25bde"
   },
   "source": [
    "If we want to both read and write a file, we can open the file in read/write mode. We can do this by using the argument `'r+'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd63f61",
   "metadata": {
    "id": "edd63f61"
   },
   "outputs": [],
   "source": [
    "nf = open('new_file.txt', 'r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c5fb1",
   "metadata": {
    "id": "653c5fb1"
   },
   "source": [
    "Now, we can read the file however we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a32cbc",
   "metadata": {
    "id": "f1a32cbc"
   },
   "outputs": [],
   "source": [
    "nf.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef59b0",
   "metadata": {
    "id": "e6ef59b0"
   },
   "source": [
    "We can also write new lines to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f069049",
   "metadata": {
    "id": "7f069049"
   },
   "outputs": [],
   "source": [
    "nf.write('This is also a new line of text.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495f550",
   "metadata": {
    "id": "c495f550"
   },
   "source": [
    "Let's check on our changes (remember we have to create a new instance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2829b8",
   "metadata": {
    "id": "6d2829b8"
   },
   "outputs": [],
   "source": [
    "nf.close()\n",
    "nf = open('new_file.txt', 'r+')\n",
    "print(nf.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c426425b",
   "metadata": {
    "id": "c426425b"
   },
   "source": [
    "The lines we've added insinuate that they have their own lines, but it seems like that's not the case. We'll have to use those special characters we say when reading the lines in Gettysburg Address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0797fef",
   "metadata": {
    "id": "b0797fef"
   },
   "outputs": [],
   "source": [
    "nf.write('\\n')\n",
    "nf.write('This is actually a new line of text.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8978b1e8",
   "metadata": {
    "id": "8978b1e8"
   },
   "outputs": [],
   "source": [
    "nf.close()\n",
    "nf = open('new_file.txt', 'r+')\n",
    "print(nf.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9321c",
   "metadata": {
    "id": "46f9321c"
   },
   "source": [
    "If we want to add multiple lines to a text file, we can use `writelines()`, with the input being a list of lines we wish to add. We still have to add the line breaks manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1bc94",
   "metadata": {
    "id": "31b1bc94"
   },
   "outputs": [],
   "source": [
    "nf.writelines(['This is a line written with writelines().\\n', 'Remember to add in the linebreaks manually.\\n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3007fa",
   "metadata": {
    "id": "0b3007fa"
   },
   "outputs": [],
   "source": [
    "nf.close()\n",
    "nf = open('new_file.txt', 'r+')\n",
    "print(nf.read())\n",
    "nf.close() # always remember to close your files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb5def4",
   "metadata": {
    "id": "8eb5def4"
   },
   "source": [
    "# I/O in `pandas`\n",
    "\n",
    "Using `open()` is a basic way to read and write the contents of files. If we want to read in large datasets, there's are even more robust ways to do so. We can use a library called `pandas`, the most popular library used for reading data in scientific programming. We'll make sure it's installed and import it as always:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6ae2c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c6ae2c2",
    "outputId": "fef0ac70-65bb-435e-d872-b65ab0564657"
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de3815",
   "metadata": {
    "id": "b8de3815"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZuEL_UoG-uD4",
   "metadata": {
    "id": "ZuEL_UoG-uD4"
   },
   "source": [
    "### Introducing `DataFrames`\n",
    "\n",
    "We can use `pandas` straight out of the box without inputting or outputting anything. We can use `pandas.DataFrame()` to generate a `DataFrame`, the `pandas` equivalent of a table. Let's say for example that I knew the names, ages, and sexes of a group of students in a programming class. To generate a `DataFrame`, I can create a dictionary of lists keyed by these three parameters, with the lists containing the corresponding data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50821542",
   "metadata": {
    "id": "50821542"
   },
   "outputs": [],
   "source": [
    "data = {'Name': ['Timothy Powers', 'Ashley Brown', 'George Rodriguez'],\n",
    "        'Age': [23, 19, 22],\n",
    "        'Sex': ['male', 'female', 'male']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eHmNXW2F9Kj-",
   "metadata": {
    "id": "eHmNXW2F9Kj-"
   },
   "source": [
    "Then, we can create a `DataFrame` using `pandas.DataFrame()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFynPALw9RAj",
   "metadata": {
    "id": "SFynPALw9RAj"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mwccxylp9ckK",
   "metadata": {
    "id": "Mwccxylp9ckK"
   },
   "source": [
    "Let's see what was generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ecc43EPP9enU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "Ecc43EPP9enU",
    "outputId": "002d730b-f3d1-4934-e721-16ae3e716cf2"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qTzoUCiA9pBj",
   "metadata": {
    "id": "qTzoUCiA9pBj"
   },
   "source": [
    "`pandas` has automatically generated a table from the dictionary we've created. The keys of that dictionary have become the column labels in the first row. The values of each key are the row elements in each column that we assigned in the lists. The row indices are inherited from the elements' indices in the lists we defined. Notice that we can mix and match data types: the Name and Sex columns contain strings, while the Age column contains integers.\n",
    "\n",
    "We can work with individual columns and assign them to variables. A column in a `DataFrame` is known as a `Series`, and we can call one the same way we'd call a key in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zRQEz7cz-rKh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRQEz7cz-rKh",
    "outputId": "94f086f2-42dd-4cae-9ee3-af2bb9a51a64"
   },
   "outputs": [],
   "source": [
    "df['Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cGqO6Lc0-viS",
   "metadata": {
    "id": "cGqO6Lc0-viS"
   },
   "source": [
    "We can create an individual `Series` using `pandas.Series()`, this time inputting a list of values. We can optionally pass the keyword argument `name` to assign a name to it. For example, let's say I wanted a `Series` containing the above students' grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apukCo6CB2ey",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apukCo6CB2ey",
    "outputId": "822c8c11-72be-4b4e-c4de-7a45d66db936"
   },
   "outputs": [],
   "source": [
    "grades = pd.Series([76, 94, 87], name='Grade')\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZjlQGF_CCAle",
   "metadata": {
    "id": "ZjlQGF_CCAle"
   },
   "source": [
    "We can do a multitude of simple statistical analyses of `DataFrame` objects. For example, let's say I wanted to know the maximum age in `df`. I can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awnc3O5fCcOg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awnc3O5fCcOg",
    "outputId": "00df6e15-22ea-47ac-cfc7-7f8fdd6fd915"
   },
   "outputs": [],
   "source": [
    "df['Age'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bIolllV3CgUA",
   "metadata": {
    "id": "bIolllV3CgUA"
   },
   "source": [
    "Or, say I wanted the mean grade in the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58JM7qtVCm9r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "58JM7qtVCm9r",
    "outputId": "9659129c-fbaa-4e2c-97c2-9c605fa42d33"
   },
   "outputs": [],
   "source": [
    "grades.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QWyaJmWOCpUy",
   "metadata": {
    "id": "QWyaJmWOCpUy"
   },
   "source": [
    "There's another method, `DataFrame.describe()`, that gives some basic statistics of all the numerical data in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cBUfJ_eCxrY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "6cBUfJ_eCxrY",
    "outputId": "23fff820-33e6-4b14-d653-b27c0ad0497f"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A3-S_xM7Czhq",
   "metadata": {
    "id": "A3-S_xM7Czhq"
   },
   "source": [
    "This only shows the statistics for the series 'Age' since it's the only numerical series in `df`. We can do the same with the standalone series `grades`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hEqCrTtUDStP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hEqCrTtUDStP",
    "outputId": "c0953b90-163d-4ca6-d327-806ea9807661"
   },
   "outputs": [],
   "source": [
    "grades.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33Bk482lDVZV",
   "metadata": {
    "id": "33Bk482lDVZV"
   },
   "source": [
    "### Reading and Writing Tables\n",
    "\n",
    "It's nice to have tables in your current notebook or program, but the real power of `pandas` lies in being able to do I/O with large datasets. There are two main categories of functions in `pandas` that allow us to read in and export files of many different types. The `read_*()` functions are used to read in data as a `DataFrame`, and the `to_*()` functions are used to export a `DataFrame` to an external file. The asterisks are wildcards that refer to different file types; we can import and export anything from *comma-separated value* (CSV) files to *fixed-width files* (FWF) to Excel spreadsheets (XLSX).\n",
    "\n",
    "For example, let's say I wanted to save `df` as a `csv` file. I can do so using `to_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L8UE08J_Fd7n",
   "metadata": {
    "id": "L8UE08J_Fd7n"
   },
   "outputs": [],
   "source": [
    "df.to_csv('class.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iPpHLV1WF5hL",
   "metadata": {
    "id": "iPpHLV1WF5hL"
   },
   "source": [
    "I can call the same file using `read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sPyPKUpfF_Fy",
   "metadata": {
    "id": "sPyPKUpfF_Fy"
   },
   "outputs": [],
   "source": [
    "df_from_csv = pd.read_csv('class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UKfdaYOdGD1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "UKfdaYOdGD1n",
    "outputId": "d145f1b0-824f-438d-9307-98e713908f72"
   },
   "outputs": [],
   "source": [
    "df_from_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "U8ceZ0ZsGgRX",
   "metadata": {
    "id": "U8ceZ0ZsGgRX"
   },
   "source": [
    "We can instead save the `DataFrame` to a spreadsheet using `to_excel()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IosaxzMKGl9i",
   "metadata": {
    "id": "IosaxzMKGl9i"
   },
   "outputs": [],
   "source": [
    "df.to_excel('class.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XJOUl1tFGqHl",
   "metadata": {
    "id": "XJOUl1tFGqHl"
   },
   "source": [
    "However, we can't mix and match file types with `read_*()`. We have to make sure that the read function used to call a file matches the file type. Let's see what happens if I try calling my spreadsheet with `read_csv()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rPYsYy5oG-92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "rPYsYy5oG-92",
    "outputId": "4dad0f1b-f891-46c8-b8ff-4990d3e524f5"
   },
   "outputs": [],
   "source": [
    "df_from_ss = pd.read_csv('class.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nXckoncqIJGi",
   "metadata": {
    "id": "nXckoncqIJGi"
   },
   "source": [
    "Let's read in a csv file containing passenger data from the Titanic. Recall that we can download this from the Internet using `wget`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WqwLLiCpLeRf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WqwLLiCpLeRf",
    "outputId": "59a20dea-8a17-4066-df47-a4b14309e6d7"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TXwF27MtIe3u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "TXwF27MtIe3u",
    "outputId": "d71b7a50-a0f2-422a-b2c8-82a3d98cc266"
   },
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic.csv')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KR2irIoNLoyy",
   "metadata": {
    "id": "KR2irIoNLoyy"
   },
   "source": [
    "We can see at the bottom left that this `DataFrame` has 891 rows and 12 columns. `pandas` automatically compactifies this by showing us only the first and last few rows. If we want to specify how many rows or columns we can see, we can use the functions `head()` and `tail()`. `head(n)` prints the first `n` rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tTO6cLe8MKwv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "tTO6cLe8MKwv",
    "outputId": "ccfbe47b-696a-4fb1-d11d-344b6b3a6f9b"
   },
   "outputs": [],
   "source": [
    "titanic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r_3_zluMMTrS",
   "metadata": {
    "id": "r_3_zluMMTrS"
   },
   "source": [
    "To see the last `n` rows, use `tail(n)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVOokN0OMXdT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "pVOokN0OMXdT",
    "outputId": "42054f12-668f-4e12-f372-12d8f7b06881"
   },
   "outputs": [],
   "source": [
    "titanic.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tZtf8oMWMc4F",
   "metadata": {
    "id": "tZtf8oMWMc4F"
   },
   "source": [
    "With so many series, it's convenient to keep track of what data types each column contains. We can do so using the attribute `dtypes` on the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918PNM-SMnjR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "918PNM-SMnjR",
    "outputId": "d76ac6be-a814-4cda-8f24-a54f5baf0e4a"
   },
   "outputs": [],
   "source": [
    "titanic.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wuYNQKHUMt52",
   "metadata": {
    "id": "wuYNQKHUMt52"
   },
   "source": [
    "This `DataFrame` has three unique types: `int64`, representing integers; `float64`, representing `float`s; and `object`, representing strings.\n",
    "\n",
    "This information also shows up when we run the method `info()`, which gives some additional technical data about the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YuvvxGnVNFVi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YuvvxGnVNFVi",
    "outputId": "725cb64e-7006-435a-8470-f6c88afe5d80"
   },
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LcRma2-FNJDb",
   "metadata": {
    "id": "LcRma2-FNJDb"
   },
   "source": [
    "This shows a series-by-series breakdown of the types in each column as well as the number of non-null elements in each (i.e. how many elements are not `NaN`). `info()` also gives an approximation of how much memory the `DataFrame` takes up on the bottom.\n",
    "\n",
    "To get the number of rows and columns in a `DataFrame`, we can use the attribute `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RLdoteyhOgFI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLdoteyhOgFI",
    "outputId": "3b0d0b94-d2b9-44f7-ba98-6e2841d452c0"
   },
   "outputs": [],
   "source": [
    "titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-WwvPpdcOh9S",
   "metadata": {
    "id": "-WwvPpdcOh9S"
   },
   "source": [
    "Just like a `numpy` array, the shape of a `DataFrame` is of the form `(rows, columns)`.\n",
    "\n",
    "### Filtering Data\n",
    "\n",
    "We can filter rows and columns with many different strategies. We've already seen that individual columns can be called using `DataFrame['column name']`. We can also use this to call multiple columns at a time. For example, let's say I wanted the age and sex of every passenger aboard the Titanic. We could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bukCyN_1OhG3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "bukCyN_1OhG3",
    "outputId": "d4ba9573-274b-4ff3-cfe2-f04428e88f40"
   },
   "outputs": [],
   "source": [
    "mult_cols = titanic[['Name', 'Age', 'Sex']]\n",
    "mult_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F_OhWSpfQMtg",
   "metadata": {
    "id": "F_OhWSpfQMtg"
   },
   "source": [
    "By inputting a list of names instead of just one name, we get a new `DataFrame` with the specified columns only.\n",
    "\n",
    "Now, let's say I only want to see the passengers that survived the disaster. In the dataset, this is encoded by the Survived column, which has a value of 0 if the passenger survived and 1 if they did not. We can use a Boolean statement to see which rows have a Survived value of 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kMEkR_p0QJwX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMEkR_p0QJwX",
    "outputId": "4ee5a03c-8312-42ef-8fdc-527d796cef5a"
   },
   "outputs": [],
   "source": [
    "survived = (titanic['Survived'] == 0)\n",
    "survived"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eGg6cRQFRfTO",
   "metadata": {
    "id": "eGg6cRQFRfTO"
   },
   "source": [
    "This returns a `Series` of bools based on whether the condition is satisfied or not. We can pass this as an index in place of a column name to filter out rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wWOVeV9fRs_M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wWOVeV9fRs_M",
    "outputId": "076ce00b-b147-43ea-aac4-8cbb67df1e53"
   },
   "outputs": [],
   "source": [
    "survivors = titanic[survived]\n",
    "survivors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gcyxv1YDSA9o",
   "metadata": {
    "id": "Gcyxv1YDSA9o"
   },
   "source": [
    "Now, we have a dataset containing only the rows for which the above condition returned `True`. We can check how many people survived using `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "It3HeUG9SRDH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "It3HeUG9SRDH",
    "outputId": "1509f6dc-0e3d-404b-c83c-b173ddd0a7e6"
   },
   "outputs": [],
   "source": [
    "survivors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rvqyVjIbSZZa",
   "metadata": {
    "id": "rvqyVjIbSZZa"
   },
   "source": [
    "A good sanity check would be to ensure that the number of people who survived plus the number of people who didn't is equal to the total number of people. We can make a second `DataFrame` using the opposite truth statement to get the number of casualties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pxh-LhE2SuSo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "pxh-LhE2SuSo",
    "outputId": "3aa86791-29d5-484b-9dd2-55d3128dd904"
   },
   "outputs": [],
   "source": [
    "casualty = (titanic['Survived'] == 1)\n",
    "casualties = titanic[casualty]\n",
    "casualties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XmqNQnLpTFvG",
   "metadata": {
    "id": "XmqNQnLpTFvG"
   },
   "source": [
    "We can use the shapes to verify that the survivors plus casualties equals the total passenger count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55J-denCTNc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55J-denCTNc4",
    "outputId": "8880bbbd-2dc5-479b-b0b4-9a607d0c9ac3"
   },
   "outputs": [],
   "source": [
    "survivors.shape[0] + casualties.shape[0] == titanic.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9TWvjFTkTYBx",
   "metadata": {
    "id": "9TWvjFTkTYBx"
   },
   "source": [
    "It's usually good practice to do simple sanity checks like this when reading in data to make sure there's no weird or erroneous results.\n",
    "\n",
    "Let's say I wanted to call specific rows and columns at the same time. For example, let's say I only want the names of the people who survived the Titanic disaster. I can do so using the `loc` operator for my `DataFrame`, which uses the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hu8xiy55UmHh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hu8xiy55UmHh",
    "outputId": "35769f85-445f-48a4-e846-2638c318c62f"
   },
   "outputs": [],
   "source": [
    "survivor_names = titanic.loc[survived, 'Name']\n",
    "survivor_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n2pDQxSFVGyx",
   "metadata": {
    "id": "n2pDQxSFVGyx"
   },
   "source": [
    "The first \"index\" specifies which rows we want to keep, while the second specifies which columns we want to keep.\n",
    "\n",
    "If we instead want to select rows and columns based on their positions in the table, we can use `iloc`, which has a similar syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aLZO01SLUyN8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "aLZO01SLUyN8",
    "outputId": "ce8f0175-fbc0-481e-a9a2-f069d1b0282d"
   },
   "outputs": [],
   "source": [
    "arb_vals = titanic.iloc[5:15, 3:5]\n",
    "arb_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mdfbSwmEVuz5",
   "metadata": {
    "id": "mdfbSwmEVuz5"
   },
   "source": [
    "The first index now contains the slice of desired rows, while the second contains a slice of desired columns.\n",
    "\n",
    "### Cleaning Up Data\n",
    "\n",
    "You can't guarantee that a data set you load in will be perfect. Oftentimes, you'll need to use filtering techniques to ensure that data analyses will go smoothly.\n",
    "\n",
    "Let's use another dataset to demonstrate this. It's called `workout_data.fwf`, signifying it's a fixed-width file; we'll use `read_fwf()` to read it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7JrlxMmGZ19E",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7JrlxMmGZ19E",
    "outputId": "9fe18183-ded2-461c-9494-bb6c922d74cd"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/acorreia61201/SAOPythonPrimer/main/files/workout_data.fwf\n",
    "workout = pd.read_fwf('workout_data.fwf')\n",
    "workout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34WEPYuJaDGs",
   "metadata": {
    "id": "34WEPYuJaDGs"
   },
   "source": [
    "We can see a bunch of problems with this data set. There's a bunch of NaNs in the data, one of the entries in the Duration column is an extreme outlier, and one of the entries in the Date column is not a string like the others. We need a way to programmatically handle these issues when doing data analyses.\n",
    "\n",
    "First, we'll remove any rows that contain empty cells. To do that, we can use a method `dropna()`, which does as it implies; it drops any rows that contain NaNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J91HJeiCcG-B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "J91HJeiCcG-B",
    "outputId": "476a97cc-8373-4844-e4b0-2ad498a436d9"
   },
   "outputs": [],
   "source": [
    "workout_nonan = workout.dropna()\n",
    "workout_nonan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Cz9Mi2BcREt",
   "metadata": {
    "id": "4Cz9Mi2BcREt"
   },
   "source": [
    "It works as advertised; there's now no empty cells in the new `DataFrame`. Notice that this creates a new object rather than modifying the old one; it's generally good practice in data analysis to save the initial data, even if it is erroneous. If we want to change this behavior, we can use the keyword argument `inplace`, which modifies the `DataFrame` in-place if `True`. \n",
    "\n",
    "Let's handle the erroneous types in the Date column. We'll use `dtypes` to see what this type should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bPm5-WTe28_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bPm5-WTe28_",
    "outputId": "9d87fd28-0546-4152-f3ec-5c1f5501b3a8"
   },
   "outputs": [],
   "source": [
    "workout_nonan.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_O9SUGhifHO3",
   "metadata": {
    "id": "_O9SUGhifHO3"
   },
   "source": [
    "As we can see by observation, the entries in tha Date column should be strings. In this instance, `pandas` has a special data type, `datetime`, which is essentially a string that can be interpreted as a date or time. We can use the function `to_datetime()` to convert the Date column to `datetime` objects. The input is the `Series` or `DataFrame` we want to convert, and we have to remember to manually do an in-place modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "odAjnEZGfF7k",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "odAjnEZGfF7k",
    "outputId": "0b004534-ecfe-4c4b-a70e-8547c0738dc2"
   },
   "outputs": [],
   "source": [
    "workout_nonan['Date'] = pd.to_datetime(workout_nonan['Date'])\n",
    "workout_nonan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lnPd8yXfnMis",
   "metadata": {
    "id": "lnPd8yXfnMis"
   },
   "source": [
    "Notice that it changed the strings, but now the column is consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6hoHlqSOlBP3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hoHlqSOlBP3",
    "outputId": "b09cc65f-cd55-46ed-9ed3-1a281006621a"
   },
   "outputs": [],
   "source": [
    "workout_nonan.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UTzF8_FchOIm",
   "metadata": {
    "id": "UTzF8_FchOIm"
   },
   "source": [
    "We may also run into issues where datasets have duplicated rows. Let's say that the dataset above should only have one entry per day. By observation, we can see that rows 11 and 12 are likely duplicates. `pandas` has a function specially designed for this called `duplicated()`. It returns a Boolean for each row that is duplicated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oijdlg3MgbLO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oijdlg3MgbLO",
    "outputId": "1658c850-90fd-430e-afb7-697ecca1e704"
   },
   "outputs": [],
   "source": [
    "workout_nonan.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RBI6lRBwpHZB",
   "metadata": {
    "id": "RBI6lRBwpHZB"
   },
   "source": [
    "Here, the function marked row 12 as a duplicate of row 11. To remove these, we can use another specialized function `drop_duplicates()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zmmZZuU7pFjc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 928
    },
    "id": "zmmZZuU7pFjc",
    "outputId": "80dc6211-dc18-4dc0-cee4-521e53217470"
   },
   "outputs": [],
   "source": [
    "workout_nodupes = workout_nonan.drop_duplicates()\n",
    "workout_nodupes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SEQ6ePY8pc0h",
   "metadata": {
    "id": "SEQ6ePY8pc0h"
   },
   "source": [
    "The hardest errors to catch are conceptual errors, which may arise from typos from data entry. For example, looking in the Duration column, we see one value of 450 among a bunch of 45s and 60s. If we're interpreting this column as lengths of workout sessions in minutes, a value of 450 (7.5 hours) is pretty unlikely. \n",
    "\n",
    "We could replace this value using `loc()`, but a more programmatic approach would be to apply some filter that either locates or handles typos like this. In this case, we'll set the upper limit for a reasonable workout to be 120 minutes, or 2 hours. To iterate, we can use the attribute `index`, which contains an iterable of the indices of the rows in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkrRCumGrAdu",
   "metadata": {
    "id": "zkrRCumGrAdu"
   },
   "outputs": [],
   "source": [
    "for i in workout_nodupes.index: # iterate over rows in DataFrame\n",
    "    if workout_nodupes.loc[i, 'Duration'] > 120: # check if current row's duration > 120\n",
    "        workout_nodupes.drop(i, inplace=True) #delete if it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cwEpmLy3rbme",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "id": "cwEpmLy3rbme",
    "outputId": "fd62a2a4-8733-4ec5-853d-0c08f0866303"
   },
   "outputs": [],
   "source": [
    "workout_good = workout_nodupes\n",
    "workout_good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Bghtk-B2sEx2",
   "metadata": {
    "id": "Bghtk-B2sEx2"
   },
   "source": [
    "### Data Analysis\n",
    "\n",
    "Once we have a cleaned up dataset that passes our sanity checks, we can do some data analysis. We've already seen some simple calculations using `describe()`, but `pandas` has some functionality built-in to aid in analysis.\n",
    "\n",
    "`pandas` has a built-in method `corr()`, which calculates the *correlation matrix* between all the numerical columns in the dataset. Let's test it on our clean data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bvgfiXEDtZ9z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "bvgfiXEDtZ9z",
    "outputId": "b6df6d83-624f-43f1-cd91-ec5940dbff15"
   },
   "outputs": [],
   "source": [
    "workout_good.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6K-0bY-UtgyE",
   "metadata": {
    "id": "6K-0bY-UtgyE"
   },
   "source": [
    "The correlation matrix measures how well two variables follow a linear relationship. Its values range from -1 to 1, where 1 indicates a perfect positive linear relationship between variables, -1 indicates a perfect negative linear relationship, and 0 represents no correlation. \n",
    "\n",
    "As you can see above, every column has a perfect correlation with itself, which is always true no matter what data you're looking at. The correlations with other columns are all pretty weak, the highest correlation is ~0.5 between Pulse and Calories, which indicates a moderate, but not great, correlation.\n",
    "This essentially indicates that no one column in our data can be used to predict the linear behavior of any other.\n",
    "\n",
    "Additionally, `pandas` has support for any `matplotlib` plotting functions, which we can call as methods to the `DataFrame` we want to visualize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H5cEqof_tb06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "id": "H5cEqof_tb06",
    "outputId": "4636a7a6-6e73-4836-8c90-fae3fc23adee"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "workout_good.plot('Date', 'Calories') # plot calories burned every day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qh62WFm6u46o",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "Qh62WFm6u46o",
    "outputId": "d1c51e50-9844-4ff2-f2c8-beea14685ce6"
   },
   "outputs": [],
   "source": [
    "workout_good.plot.scatter(x='Pulse', y='Calories') # scatterplot of calories burned vs avg pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JLX0f-nWvvvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "JLX0f-nWvvvK",
    "outputId": "4b64078e-44e3-41ef-a9fe-7ca553f8370e"
   },
   "outputs": [],
   "source": [
    "workout_good['Calories'].plot.hist() # plot a histogram of calories burned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wdDcqLChwgRo",
   "metadata": {
    "id": "wdDcqLChwgRo"
   },
   "source": [
    "If you're more comfortable with non-`pandas` syntax or want to use another method of analysis, you can pass `Series` objects as if they were any other iterable. For more general use, you can convert `Series` objects to `numpy` arrays using `to_numpy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sur3Ixyqv3_l",
   "metadata": {
    "id": "sur3Ixyqv3_l"
   },
   "outputs": [],
   "source": [
    "calories = workout_good['Calories'].to_numpy()\n",
    "pulses = workout_good['Pulse'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2DDi9piIw7lZ",
   "metadata": {
    "id": "2DDi9piIw7lZ"
   },
   "source": [
    "We can now use these however we've used `numpy` arrays thus far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qDu0KlIkw6nL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "qDu0KlIkw6nL",
    "outputId": "3132226b-fba4-46ce-8a0b-9a7a4ddbf6a6"
   },
   "outputs": [],
   "source": [
    "plt.scatter(pulses, calories) # plot a scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1QD2KNKCxVPT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1QD2KNKCxVPT",
    "outputId": "7e1374a2-d367-4ce5-b5eb-aa59d58f3a85"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "calories.sum() # get the total number of calories burned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XOgsBPmxxAsl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOgsBPmxxAsl",
    "outputId": "ff48361c-df91-4f98-fad0-3f28a43f6040"
   },
   "outputs": [],
   "source": [
    "np.dot(calories, pulses) # take a dot product...even if it doesn't make sense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iprSA3gfyCX5",
   "metadata": {
    "id": "iprSA3gfyCX5"
   },
   "source": [
    "As always, this is just scratching the surface of what can be done with `pandas`; the official documentation can be found at https://pandas.pydata.org/docs/reference/index.html."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
